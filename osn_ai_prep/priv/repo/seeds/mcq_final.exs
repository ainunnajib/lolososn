# Final MCQ Questions to reach 500+ (80+ questions)
# Run with: mix run priv/repo/seeds/mcq_final.exs

alias OsnAiPrep.Repo
alias OsnAiPrep.Mcq.Question
import Ecto.Query

defmodule FinalSeeder do
  def insert_all(questions) do
    for q <- questions do
      %Question{}
      |> Question.changeset(q)
      |> Repo.insert!()
    end
    length(questions)
  end
end

final_questions = [
  # More Python/Pandas (20)
  %{question_en: "What is the difference between loc and iloc in Pandas?", question_id: "Apa perbedaan antara loc dan iloc di Pandas?", option_a_en: "loc uses labels, iloc uses integer positions", option_a_id: "loc menggunakan label, iloc menggunakan posisi integer", option_b_en: "They are the same", option_b_id: "Keduanya sama", option_c_en: "iloc uses labels", option_c_id: "iloc menggunakan label", option_d_en: "loc is faster", option_d_id: "loc lebih cepat", correct_answer: "A", explanation_en: "df.loc['row_name'] selects by label, df.iloc[0] selects by position.", explanation_id: "df.loc['row_name'] memilih berdasarkan label, df.iloc[0] memilih berdasarkan posisi.", topic: "python_basics", difficulty: "easy", competition: "noai_prelim"},
  %{question_en: "How do you handle missing values in Pandas?", question_id: "Bagaimana cara menangani nilai yang hilang di Pandas?", option_a_en: "Using dropna() to remove or fillna() to fill", option_a_id: "Menggunakan dropna() untuk menghapus atau fillna() untuk mengisi", option_b_en: "Missing values are ignored automatically", option_b_id: "Nilai yang hilang diabaikan secara otomatis", option_c_en: "Replace with None", option_c_id: "Ganti dengan None", option_d_en: "Delete the column", option_d_id: "Hapus kolom", correct_answer: "A", explanation_en: "dropna() removes rows/columns with NaN. fillna() replaces with specified value or method.", explanation_id: "dropna() menghapus baris/kolom dengan NaN. fillna() mengganti dengan nilai atau metode yang ditentukan.", topic: "python_basics", difficulty: "easy", competition: "noai_prelim"},
  %{question_en: "What does df.groupby() do?", question_id: "Apa yang dilakukan df.groupby()?", option_a_en: "Groups data by column values for aggregation operations", option_a_id: "Mengelompokkan data berdasarkan nilai kolom untuk operasi agregasi", option_b_en: "Sorts the DataFrame", option_b_id: "Mengurutkan DataFrame", option_c_en: "Removes duplicates", option_c_id: "Menghapus duplikat", option_d_en: "Merges DataFrames", option_d_id: "Menggabungkan DataFrame", correct_answer: "A", explanation_en: "groupby splits data into groups, then applies functions like sum(), mean(), count().", explanation_id: "groupby membagi data menjadi grup, lalu menerapkan fungsi seperti sum(), mean(), count().", topic: "python_basics", difficulty: "easy", competition: "noai_prelim"},
  %{question_en: "What is the purpose of df.merge()?", question_id: "Apa tujuan dari df.merge()?", option_a_en: "Combines DataFrames based on common columns (like SQL JOIN)", option_a_id: "Menggabungkan DataFrame berdasarkan kolom yang sama (seperti SQL JOIN)", option_b_en: "Appends rows", option_b_id: "Menambahkan baris", option_c_en: "Splits DataFrames", option_c_id: "Memisahkan DataFrame", option_d_en: "Removes columns", option_d_id: "Menghapus kolom", correct_answer: "A", explanation_en: "merge combines DataFrames on key columns: inner, left, right, outer joins supported.", explanation_id: "merge menggabungkan DataFrame pada kolom kunci: inner, left, right, outer join didukung.", topic: "python_basics", difficulty: "medium", competition: "noai_prelim"},
  %{question_en: "What does pd.concat() do?", question_id: "Apa yang dilakukan pd.concat()?", option_a_en: "Concatenates DataFrames along rows or columns", option_a_id: "Menggabungkan DataFrame sepanjang baris atau kolom", option_b_en: "Merges on keys", option_b_id: "Menggabung pada kunci", option_c_en: "Creates new DataFrame", option_c_id: "Membuat DataFrame baru", option_d_en: "Filters data", option_d_id: "Memfilter data", correct_answer: "A", explanation_en: "concat stacks DataFrames: axis=0 for rows (default), axis=1 for columns.", explanation_id: "concat menumpuk DataFrame: axis=0 untuk baris (default), axis=1 untuk kolom.", topic: "python_basics", difficulty: "easy", competition: "noai_prelim"},
  %{question_en: "What is vectorized operation in NumPy?", question_id: "Apa itu operasi vektorisasi di NumPy?", option_a_en: "Operations applied element-wise to entire arrays without explicit loops", option_a_id: "Operasi yang diterapkan element-wise ke seluruh array tanpa loop eksplisit", option_b_en: "Using vectors in code", option_b_id: "Menggunakan vektor dalam kode", option_c_en: "Loop operations", option_c_id: "Operasi loop", option_d_en: "Vector graphics", option_d_id: "Grafik vektor", correct_answer: "A", explanation_en: "Vectorization is much faster than Python loops because it uses optimized C code.", explanation_id: "Vektorisasi jauh lebih cepat dari loop Python karena menggunakan kode C yang dioptimalkan.", topic: "numpy", difficulty: "medium", competition: "noai_prelim"},
  %{question_en: "What is the difference between np.dot() and @?", question_id: "Apa perbedaan antara np.dot() dan @?", option_a_en: "For 2D arrays they are the same (matrix multiplication)", option_a_id: "Untuk array 2D keduanya sama (perkalian matriks)", option_b_en: "@ is element-wise", option_b_id: "@ adalah element-wise", option_c_en: "dot is deprecated", option_c_id: "dot sudah usang", option_d_en: "@ doesn't work on matrices", option_d_id: "@ tidak bekerja pada matriks", correct_answer: "A", explanation_en: "A @ B and np.dot(A, B) both perform matrix multiplication for 2D arrays.", explanation_id: "A @ B dan np.dot(A, B) keduanya melakukan perkalian matriks untuk array 2D.", topic: "numpy", difficulty: "medium", competition: "noai_prelim"},
  %{question_en: "What does plt.subplots() return?", question_id: "Apa yang dikembalikan plt.subplots()?", option_a_en: "A figure and axes objects for creating multiple plots", option_a_id: "Objek figure dan axes untuk membuat beberapa plot", option_b_en: "Just a plot", option_b_id: "Hanya plot", option_c_en: "A list of figures", option_c_id: "Daftar figure", option_d_en: "None", option_d_id: "None", correct_answer: "A", explanation_en: "fig, ax = plt.subplots() returns figure container and axes for plotting.", explanation_id: "fig, ax = plt.subplots() mengembalikan container figure dan axes untuk plotting.", topic: "python_basics", difficulty: "easy", competition: "noai_prelim"},
  %{question_en: "What is a DataFrame index?", question_id: "Apa itu index DataFrame?", option_a_en: "Row labels used to identify and access data", option_a_id: "Label baris yang digunakan untuk mengidentifikasi dan mengakses data", option_b_en: "Column numbers", option_b_id: "Nomor kolom", option_c_en: "Data types", option_c_id: "Tipe data", option_d_en: "File location", option_d_id: "Lokasi file", correct_answer: "A", explanation_en: "Index can be integers, strings, datetime. Set with set_index(), reset with reset_index().", explanation_id: "Index bisa integer, string, datetime. Atur dengan set_index(), reset dengan reset_index().", topic: "python_basics", difficulty: "easy", competition: "noai_prelim"},
  %{question_en: "How do you read a CSV file in Pandas?", question_id: "Bagaimana cara membaca file CSV di Pandas?", option_a_en: "pd.read_csv('filename.csv')", option_a_id: "pd.read_csv('filename.csv')", option_b_en: "pd.load('filename.csv')", option_b_id: "pd.load('filename.csv')", option_c_en: "pd.open_csv('filename.csv')", option_c_id: "pd.open_csv('filename.csv')", option_d_en: "pd.csv('filename.csv')", option_d_id: "pd.csv('filename.csv')", correct_answer: "A", explanation_en: "read_csv supports many parameters: sep, header, index_col, encoding, etc.", explanation_id: "read_csv mendukung banyak parameter: sep, header, index_col, encoding, dll.", topic: "python_basics", difficulty: "easy", competition: "noai_prelim"},
  # More ML practical (20)
  %{question_en: "What is train_test_split used for?", question_id: "Untuk apa train_test_split digunakan?", option_a_en: "Splitting data into training and testing sets", option_a_id: "Membagi data menjadi set training dan testing", option_b_en: "Training models", option_b_id: "Melatih model", option_c_en: "Testing models", option_c_id: "Menguji model", option_d_en: "Validating results", option_d_id: "Memvalidasi hasil", correct_answer: "A", explanation_en: "Typically 80% train, 20% test. shuffle=True randomizes, random_state for reproducibility.", explanation_id: "Biasanya 80% train, 20% test. shuffle=True mengacak, random_state untuk reprodusibilitas.", topic: "ml_basics", difficulty: "easy", competition: "noai_prelim"},
  %{question_en: "What is GridSearchCV?", question_id: "Apa itu GridSearchCV?", option_a_en: "Exhaustive search over specified parameter grid with cross-validation", option_a_id: "Pencarian menyeluruh pada grid parameter yang ditentukan dengan cross-validation", option_b_en: "Grid-based model", option_b_id: "Model berbasis grid", option_c_en: "CSV grid reader", option_c_id: "Pembaca grid CSV", option_d_en: "Visualization tool", option_d_id: "Alat visualisasi", correct_answer: "A", explanation_en: "GridSearchCV tries all parameter combinations and selects best via cross-validation score.", explanation_id: "GridSearchCV mencoba semua kombinasi parameter dan memilih yang terbaik melalui skor cross-validation.", topic: "ml_basics", difficulty: "medium", competition: "noai_prelim"},
  %{question_en: "What is RandomizedSearchCV?", question_id: "Apa itu RandomizedSearchCV?", option_a_en: "Samples random parameter combinations instead of exhaustive search", option_a_id: "Mengambil sampel kombinasi parameter acak alih-alih pencarian menyeluruh", option_b_en: "Random model selection", option_b_id: "Pemilihan model acak", option_c_en: "Randomizing data", option_c_id: "Mengacak data", option_d_en: "Random cross-validation", option_d_id: "Cross-validation acak", correct_answer: "A", explanation_en: "RandomizedSearchCV is faster than GridSearchCV for large parameter spaces.", explanation_id: "RandomizedSearchCV lebih cepat dari GridSearchCV untuk ruang parameter besar.", topic: "ml_basics", difficulty: "medium", competition: "noai_prelim"},
  %{question_en: "What is a pipeline in scikit-learn?", question_id: "Apa itu pipeline di scikit-learn?", option_a_en: "A sequence of data transformations and a final estimator chained together", option_a_id: "Urutan transformasi data dan estimator akhir yang dirantai bersama", option_b_en: "Data transfer pipeline", option_b_id: "Pipeline transfer data", option_c_en: "Model stacking", option_c_id: "Penumpukan model", option_d_en: "Parallel processing", option_d_id: "Pemrosesan paralel", correct_answer: "A", explanation_en: "Pipeline ensures preprocessing steps are applied consistently during training and prediction.", explanation_id: "Pipeline memastikan langkah preprocessing diterapkan secara konsisten selama training dan prediksi.", topic: "ml_basics", difficulty: "medium", competition: "noai_prelim"},
  %{question_en: "What is StandardScaler?", question_id: "Apa itu StandardScaler?", option_a_en: "Transforms features to have zero mean and unit variance", option_a_id: "Mentransformasi fitur agar memiliki mean nol dan variance unit", option_b_en: "Scales to 0-1 range", option_b_id: "Menskalakan ke rentang 0-1", option_c_en: "Removes outliers", option_c_id: "Menghapus outlier", option_d_en: "Normalizes labels", option_d_id: "Menormalisasi label", correct_answer: "A", explanation_en: "StandardScaler: z = (x - mean) / std. Important for algorithms sensitive to feature scales.", explanation_id: "StandardScaler: z = (x - mean) / std. Penting untuk algoritma yang sensitif terhadap skala fitur.", topic: "ml_basics", difficulty: "easy", competition: "noai_prelim"},
  %{question_en: "What is MinMaxScaler?", question_id: "Apa itu MinMaxScaler?", option_a_en: "Scales features to a specified range, typically 0 to 1", option_a_id: "Menskalakan fitur ke rentang tertentu, biasanya 0 hingga 1", option_b_en: "Same as StandardScaler", option_b_id: "Sama dengan StandardScaler", option_c_en: "Finds min and max", option_c_id: "Menemukan min dan max", option_d_en: "Removes extreme values", option_d_id: "Menghapus nilai ekstrem", correct_answer: "A", explanation_en: "MinMaxScaler: x_scaled = (x - min) / (max - min). Preserves zero for sparse data.", explanation_id: "MinMaxScaler: x_scaled = (x - min) / (max - min). Mempertahankan nol untuk data sparse.", topic: "ml_basics", difficulty: "easy", competition: "noai_prelim"},
  %{question_en: "What does model.fit() do?", question_id: "Apa yang dilakukan model.fit()?", option_a_en: "Trains the model on the provided training data", option_a_id: "Melatih model pada data training yang disediakan", option_b_en: "Fits data to screen", option_b_id: "Menyesuaikan data ke layar", option_c_en: "Saves the model", option_c_id: "Menyimpan model", option_d_en: "Evaluates the model", option_d_id: "Mengevaluasi model", correct_answer: "A", explanation_en: "fit() learns patterns from X_train, y_train. Model parameters are updated.", explanation_id: "fit() mempelajari pola dari X_train, y_train. Parameter model diperbarui.", topic: "ml_basics", difficulty: "easy", competition: "noai_prelim"},
  %{question_en: "What does model.predict() do?", question_id: "Apa yang dilakukan model.predict()?", option_a_en: "Makes predictions on new data using the trained model", option_a_id: "Membuat prediksi pada data baru menggunakan model yang dilatih", option_b_en: "Trains the model", option_b_id: "Melatih model", option_c_en: "Evaluates performance", option_c_id: "Mengevaluasi performa", option_d_en: "Preprocesses data", option_d_id: "Memproses data awal", correct_answer: "A", explanation_en: "predict() uses learned parameters to output predictions for new input X.", explanation_id: "predict() menggunakan parameter yang dipelajari untuk menghasilkan prediksi untuk input X baru.", topic: "ml_basics", difficulty: "easy", competition: "noai_prelim"},
  %{question_en: "What is the score() method in scikit-learn?", question_id: "Apa itu metode score() di scikit-learn?", option_a_en: "Returns the default evaluation metric for the model", option_a_id: "Mengembalikan metrik evaluasi default untuk model", option_b_en: "Gives exam scores", option_b_id: "Memberikan skor ujian", option_c_en: "Ranks features", option_c_id: "Memberi peringkat fitur", option_d_en: "Scores data quality", option_d_id: "Menilai kualitas data", correct_answer: "A", explanation_en: "For classifiers: accuracy. For regressors: R² score. Higher is better.", explanation_id: "Untuk classifier: akurasi. Untuk regressor: skor R². Lebih tinggi lebih baik.", topic: "ml_basics", difficulty: "easy", competition: "noai_prelim"},
  %{question_en: "What is the purpose of fit_transform()?", question_id: "Apa tujuan dari fit_transform()?", option_a_en: "Fits to training data and transforms it in one step", option_a_id: "Menyesuaikan ke data training dan mentransformasinya dalam satu langkah", option_b_en: "Just fitting", option_b_id: "Hanya fitting", option_c_en: "Just transforming", option_c_id: "Hanya transforming", option_d_en: "Validation", option_d_id: "Validasi", correct_answer: "A", explanation_en: "fit_transform = fit() + transform(). Use on training data. Use only transform() on test data.", explanation_id: "fit_transform = fit() + transform(). Gunakan pada data training. Gunakan hanya transform() pada data test.", topic: "ml_basics", difficulty: "medium", competition: "noai_prelim"},
  # More PyTorch (20)
  %{question_en: "What is a PyTorch tensor?", question_id: "Apa itu tensor PyTorch?", option_a_en: "A multi-dimensional array similar to NumPy array but with GPU support", option_a_id: "Array multi-dimensi mirip array NumPy tapi dengan dukungan GPU", option_b_en: "A string type", option_b_id: "Tipe string", option_c_en: "A function", option_c_id: "Fungsi", option_d_en: "A model layer", option_d_id: "Layer model", correct_answer: "A", explanation_en: "Tensors are the fundamental data structure in PyTorch. Support autograd for gradients.", explanation_id: "Tensor adalah struktur data fundamental di PyTorch. Mendukung autograd untuk gradient.", topic: "neural_networks", difficulty: "easy", competition: "noai_prelim"},
  %{question_en: "What does requires_grad=True do?", question_id: "Apa yang dilakukan requires_grad=True?", option_a_en: "Enables automatic gradient computation for the tensor", option_a_id: "Mengaktifkan komputasi gradient otomatis untuk tensor", option_b_en: "Requires gradient descent", option_b_id: "Membutuhkan gradient descent", option_c_en: "Disables gradients", option_c_id: "Menonaktifkan gradient", option_d_en: "Validates gradients", option_d_id: "Memvalidasi gradient", correct_answer: "A", explanation_en: "Tensors with requires_grad track operations for backward pass. Model parameters have this True.", explanation_id: "Tensor dengan requires_grad melacak operasi untuk backward pass. Parameter model memiliki ini True.", topic: "neural_networks", difficulty: "medium", competition: "noai_prelim"},
  %{question_en: "What does loss.backward() do?", question_id: "Apa yang dilakukan loss.backward()?", option_a_en: "Computes gradients of loss with respect to all parameters", option_a_id: "Menghitung gradient loss terhadap semua parameter", option_b_en: "Moves loss backward", option_b_id: "Memindahkan loss mundur", option_c_en: "Reduces loss", option_c_id: "Mengurangi loss", option_d_en: "Saves the loss", option_d_id: "Menyimpan loss", correct_answer: "A", explanation_en: "backward() propagates gradients through the computational graph using chain rule.", explanation_id: "backward() menyebarkan gradient melalui graf komputasi menggunakan chain rule.", topic: "neural_networks", difficulty: "medium", competition: "noai_prelim"},
  %{question_en: "What does optimizer.step() do?", question_id: "Apa yang dilakukan optimizer.step()?", option_a_en: "Updates model parameters using computed gradients", option_a_id: "Memperbarui parameter model menggunakan gradient yang dihitung", option_b_en: "Takes a step forward", option_b_id: "Mengambil langkah maju", option_c_en: "Computes gradients", option_c_id: "Menghitung gradient", option_d_en: "Evaluates model", option_d_id: "Mengevaluasi model", correct_answer: "A", explanation_en: "step() applies optimization algorithm (SGD, Adam) to update weights based on gradients.", explanation_id: "step() menerapkan algoritma optimisasi (SGD, Adam) untuk memperbarui bobot berdasarkan gradient.", topic: "neural_networks", difficulty: "medium", competition: "noai_prelim"},
  %{question_en: "Why call optimizer.zero_grad()?", question_id: "Mengapa memanggil optimizer.zero_grad()?", option_a_en: "To clear accumulated gradients before computing new ones", option_a_id: "Untuk menghapus gradient yang terakumulasi sebelum menghitung yang baru", option_b_en: "To start optimization", option_b_id: "Untuk memulai optimisasi", option_c_en: "To set learning rate to zero", option_c_id: "Untuk mengatur learning rate ke nol", option_d_en: "To reset the model", option_d_id: "Untuk mereset model", correct_answer: "A", explanation_en: "PyTorch accumulates gradients by default. zero_grad() clears them for each new batch.", explanation_id: "PyTorch mengakumulasi gradient secara default. zero_grad() menghapusnya untuk setiap batch baru.", topic: "neural_networks", difficulty: "medium", competition: "noai_prelim"},
  %{question_en: "What is nn.Module in PyTorch?", question_id: "Apa itu nn.Module di PyTorch?", option_a_en: "Base class for all neural network modules", option_a_id: "Kelas dasar untuk semua modul neural network", option_b_en: "A single layer", option_b_id: "Satu layer", option_c_en: "Loss function class", option_c_id: "Kelas fungsi loss", option_d_en: "Optimizer class", option_d_id: "Kelas optimizer", correct_answer: "A", explanation_en: "Custom models inherit from nn.Module. Must implement __init__ and forward methods.", explanation_id: "Model kustom mewarisi dari nn.Module. Harus mengimplementasikan metode __init__ dan forward.", topic: "neural_networks", difficulty: "easy", competition: "noai_prelim"},
  %{question_en: "What does model.eval() do?", question_id: "Apa yang dilakukan model.eval()?", option_a_en: "Switches model to evaluation mode (disables dropout, uses running stats for BatchNorm)", option_a_id: "Beralih model ke mode evaluasi (menonaktifkan dropout, menggunakan statistik berjalan untuk BatchNorm)", option_b_en: "Evaluates accuracy", option_b_id: "Mengevaluasi akurasi", option_c_en: "Calculates loss", option_c_id: "Menghitung loss", option_d_en: "Stops training", option_d_id: "Menghentikan training", correct_answer: "A", explanation_en: "Use model.eval() during inference. Use model.train() to switch back for training.", explanation_id: "Gunakan model.eval() selama inferensi. Gunakan model.train() untuk beralih kembali untuk training.", topic: "neural_networks", difficulty: "medium", competition: "noai_prelim"},
  %{question_en: "What is torch.no_grad() used for?", question_id: "Untuk apa torch.no_grad() digunakan?", option_a_en: "Disables gradient computation for inference to save memory", option_a_id: "Menonaktifkan komputasi gradient untuk inferensi untuk menghemat memori", option_b_en: "Removes all gradients", option_b_id: "Menghapus semua gradient", option_c_en: "Stops training", option_c_id: "Menghentikan training", option_d_en: "Resets weights", option_d_id: "Mereset bobot", correct_answer: "A", explanation_en: "with torch.no_grad(): speeds up inference and reduces memory since gradients aren't tracked.", explanation_id: "with torch.no_grad(): mempercepat inferensi dan mengurangi memori karena gradient tidak dilacak.", topic: "neural_networks", difficulty: "medium", competition: "noai_prelim"},
  %{question_en: "What is DataLoader in PyTorch?", question_id: "Apa itu DataLoader di PyTorch?", option_a_en: "Provides batching, shuffling, and parallel data loading", option_a_id: "Menyediakan batching, shuffling, dan loading data paralel", option_b_en: "Loads data from disk", option_b_id: "Memuat data dari disk", option_c_en: "Processes images", option_c_id: "Memproses gambar", option_d_en: "Saves data", option_d_id: "Menyimpan data", correct_answer: "A", explanation_en: "DataLoader wraps Dataset, handles batching, shuffling, multiprocessing loading.", explanation_id: "DataLoader membungkus Dataset, menangani batching, shuffling, loading multiprocessing.", topic: "neural_networks", difficulty: "easy", competition: "noai_prelim"},
  %{question_en: "What is a Dataset in PyTorch?", question_id: "Apa itu Dataset di PyTorch?", option_a_en: "An abstract class representing a collection of data samples", option_a_id: "Kelas abstrak yang merepresentasikan koleksi sampel data", option_b_en: "A data file", option_b_id: "File data", option_c_en: "Training data only", option_c_id: "Hanya data training", option_d_en: "CSV reader", option_d_id: "Pembaca CSV", correct_answer: "A", explanation_en: "Custom Dataset must implement __len__ and __getitem__ methods.", explanation_id: "Dataset kustom harus mengimplementasikan metode __len__ dan __getitem__.", topic: "neural_networks", difficulty: "medium", competition: "noai_prelim"},
  # More Deep Learning concepts (20)
  %{question_en: "What is the learning rate?", question_id: "Apa itu learning rate?", option_a_en: "Step size for updating weights during optimization", option_a_id: "Ukuran langkah untuk memperbarui bobot selama optimisasi", option_b_en: "Speed of training", option_b_id: "Kecepatan training", option_c_en: "Number of epochs", option_c_id: "Jumlah epoch", option_d_en: "Batch size", option_d_id: "Ukuran batch", correct_answer: "A", explanation_en: "Too high: unstable. Too low: slow convergence. Typical range: 1e-5 to 1e-1.", explanation_id: "Terlalu tinggi: tidak stabil. Terlalu rendah: konvergensi lambat. Rentang tipikal: 1e-5 hingga 1e-1.", topic: "neural_networks", difficulty: "easy", competition: "noai_prelim"},
  %{question_en: "What is cosine annealing?", question_id: "Apa itu cosine annealing?", option_a_en: "Learning rate schedule that follows a cosine curve", option_a_id: "Jadwal learning rate yang mengikuti kurva cosine", option_b_en: "Cosine similarity", option_b_id: "Kesamaan cosine", option_c_en: "Annealing metals", option_c_id: "Annealing logam", option_d_en: "Activation function", option_d_id: "Fungsi aktivasi", correct_answer: "A", explanation_en: "Cosine annealing smoothly decreases LR, often with warm restarts.", explanation_id: "Cosine annealing menurunkan LR secara halus, sering dengan warm restart.", topic: "neural_networks", difficulty: "hard", competition: "noai_prelim"},
  %{question_en: "What is warmup in training?", question_id: "Apa itu warmup dalam training?", option_a_en: "Starting with low learning rate and gradually increasing it", option_a_id: "Memulai dengan learning rate rendah dan meningkatkannya secara bertahap", option_b_en: "Warming up GPU", option_b_id: "Memanaskan GPU", option_c_en: "Pre-training", option_c_id: "Pre-training", option_d_en: "Data augmentation", option_d_id: "Augmentasi data", correct_answer: "A", explanation_en: "Warmup stabilizes early training when gradients are large and unpredictable.", explanation_id: "Warmup menstabilkan training awal ketika gradient besar dan tidak dapat diprediksi.", topic: "neural_networks", difficulty: "medium", competition: "noai_prelim"},
  %{question_en: "What is weight decay?", question_id: "Apa itu weight decay?", option_a_en: "L2 regularization implemented in the optimizer", option_a_id: "Regularisasi L2 yang diimplementasikan dalam optimizer", option_b_en: "Weights getting smaller over time", option_b_id: "Bobot mengecil seiring waktu", option_c_en: "Gradient decay", option_c_id: "Peluruhan gradient", option_d_en: "Learning rate decay", option_d_id: "Peluruhan learning rate", correct_answer: "A", explanation_en: "Weight decay adds penalty term to loss, equivalent to L2 regularization in most cases.", explanation_id: "Weight decay menambahkan term penalti ke loss, setara dengan regularisasi L2 dalam kebanyakan kasus.", topic: "neural_networks", difficulty: "medium", competition: "noai_prelim"},
  %{question_en: "What is gradient accumulation?", question_id: "Apa itu akumulasi gradient?", option_a_en: "Summing gradients over multiple batches before updating", option_a_id: "Menjumlahkan gradient pada beberapa batch sebelum memperbarui", option_b_en: "Collecting gradient data", option_b_id: "Mengumpulkan data gradient", option_c_en: "Gradient storage", option_c_id: "Penyimpanan gradient", option_d_en: "Batch normalization", option_d_id: "Batch normalization", correct_answer: "A", explanation_en: "Gradient accumulation simulates larger batch sizes when GPU memory is limited.", explanation_id: "Akumulasi gradient mensimulasikan ukuran batch lebih besar ketika memori GPU terbatas.", topic: "neural_networks", difficulty: "hard", competition: "noai_prelim"},
  %{question_en: "What is the purpose of a validation set?", question_id: "Apa tujuan dari set validasi?", option_a_en: "To tune hyperparameters and monitor for overfitting during training", option_a_id: "Untuk menyetel hyperparameter dan memantau overfitting selama training", option_b_en: "Same as test set", option_b_id: "Sama dengan set test", option_c_en: "To train the model", option_c_id: "Untuk melatih model", option_d_en: "To validate data quality", option_d_id: "Untuk memvalidasi kualitas data", correct_answer: "A", explanation_en: "Validation set guides model selection and early stopping without touching test set.", explanation_id: "Set validasi memandu pemilihan model dan early stopping tanpa menyentuh set test.", topic: "ml_basics", difficulty: "easy", competition: "noai_prelim"},
  %{question_en: "What is k-fold cross-validation?", question_id: "Apa itu k-fold cross-validation?", option_a_en: "Splitting data into k parts, training on k-1 and validating on 1, rotating k times", option_a_id: "Membagi data menjadi k bagian, training pada k-1 dan validasi pada 1, memutar k kali", option_b_en: "Folding data k times", option_b_id: "Melipat data k kali", option_c_en: "K different models", option_c_id: "K model berbeda", option_d_en: "Parallel training", option_d_id: "Training paralel", correct_answer: "A", explanation_en: "K-fold gives more robust performance estimate than single train-test split.", explanation_id: "K-fold memberikan estimasi performa yang lebih robust daripada single train-test split.", topic: "ml_basics", difficulty: "medium", competition: "noai_prelim"},
  %{question_en: "What is model checkpointing?", question_id: "Apa itu checkpointing model?", option_a_en: "Saving model state periodically during training for recovery", option_a_id: "Menyimpan state model secara berkala selama training untuk pemulihan", option_b_en: "Checking model accuracy", option_b_id: "Memeriksa akurasi model", option_c_en: "Final model save", option_c_id: "Penyimpanan model akhir", option_d_en: "Validation", option_d_id: "Validasi", correct_answer: "A", explanation_en: "Checkpointing allows resuming training after interruption and keeping best model.", explanation_id: "Checkpointing memungkinkan melanjutkan training setelah gangguan dan menyimpan model terbaik.", topic: "neural_networks", difficulty: "easy", competition: "noai_prelim"},
  %{question_en: "What is reproducibility in ML?", question_id: "Apa itu reprodusibilitas dalam ML?", option_a_en: "Getting the same results when running the same experiment", option_a_id: "Mendapatkan hasil yang sama saat menjalankan eksperimen yang sama", option_b_en: "Copying models", option_b_id: "Menyalin model", option_c_en: "Making copies of data", option_c_id: "Membuat salinan data", option_d_en: "Model duplication", option_d_id: "Duplikasi model", correct_answer: "A", explanation_en: "Set random seeds, document versions, use deterministic operations for reproducibility.", explanation_id: "Atur random seed, dokumentasikan versi, gunakan operasi deterministik untuk reprodusibilitas.", topic: "ml_basics", difficulty: "medium", competition: "noai_prelim"},
  %{question_en: "What is inference?", question_id: "Apa itu inferensi?", option_a_en: "Using a trained model to make predictions on new data", option_a_id: "Menggunakan model terlatih untuk membuat prediksi pada data baru", option_b_en: "Drawing conclusions", option_b_id: "Menarik kesimpulan", option_c_en: "Training", option_c_id: "Training", option_d_en: "Validation", option_d_id: "Validasi", correct_answer: "A", explanation_en: "Inference is forward pass only, no backprop. Typically faster and uses less memory.", explanation_id: "Inferensi hanya forward pass, tanpa backprop. Biasanya lebih cepat dan menggunakan lebih sedikit memori.", topic: "ml_basics", difficulty: "easy", competition: "noai_prelim"}
]

IO.puts("Inserting final batch of questions...")
count = FinalSeeder.insert_all(final_questions)
IO.puts("Inserted #{count} final questions")

total = Repo.aggregate(Question, :count)
IO.puts("\n=== TOTAL MCQ QUESTIONS: #{total} ===")

# Show breakdown by topic
IO.puts("\nBreakdown by topic:")
topics = Repo.all(from q in Question, group_by: q.topic, select: {q.topic, count(q.id)})
for {topic, cnt} <- Enum.sort_by(topics, fn {_, cnt} -> -cnt end) do
  IO.puts("  #{topic}: #{cnt}")
end
